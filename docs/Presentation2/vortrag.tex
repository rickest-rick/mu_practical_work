%!TEX TS-program = pdflatex
\documentclass[10pt,%
	wide,%
	xcolor={x11names},%
	hyperref={colorlinks},%
	pantone312,%
	handout,%
	]{beamer}
\input{configBeamer.tex}
\author{Daniel Beckmann, Thomas Poschadel, Tony Prange, Joschka Strüber}
\title{Behavioral Context Recognition}
\subtitle{Praktikum Mustererkennung II}
\date{\today}

\begin{document}
\setbeamertemplate{section in toc}[sections numbered]

\begin{frame}[plain]
  \maketitle
\end{frame}

\begin{frame}[t]{Aufbau}
\tableofcontents[hidesubsections, hideothersubsections]
\end{frame}

\section{Was wir bisher gemacht haben}

\begin{frame}[t]{Kennenlernen des Datensatzes und Benutzererkennung}

\end{frame}

\begin{frame}[t]{Klassifizierung mit Tensorflow}
	\begin{columns}
		\begin{column}[t]{6cm}
			\begin{itemize}
				\item Erstellung eines ersten Netzes
				\item Training auf dem gesamten Datensatz
				\item Erste Versuche der Multi-Label-Klassifizierung
			\end{itemize}
		\end{column}
		\begin{column}[t]{6cm}
			\begin{center}
				\includegraphics[width=.85\textwidth]{img/keras_network_summary.png}
			\end{center}
		\end{column}		
	\end{columns}
\end{frame}

\begin{frame}[t]{Klassifizierung mit Tensorflow - Erste Ergebnisse}
	\begin{columns}
		\begin{column}[t]{6cm}
			\begin{center}
			\includegraphics[width=1\textwidth]{img/keras_training_loss.png}
			\end{center}
		\end{column}
		\begin{column}[t]{6cm}

		\end{column}		
	\end{columns}
\end{frame}

\begin{frame}[t]{Klassifizierung mit Tensorflow - Erste Ergebnisse}
	\begin{columns}
		\begin{column}[t]{6cm}
			\begin{center}
				\includegraphics[width=1\textwidth]{img/keras_training_loss_invalid.png}
			\end{center}
		\end{column}
		\begin{column}[t]{6cm}
			\begin{itemize}
				\item Manuelle Verifikation deutet wesentlich schlechtere Resultate an
				\item Erste Klassifizierung möglich
			\end{itemize}
			\vspace*{20px}
Probleme:
			\begin{itemize}
				\item Gewichtung der NaN-Labels 
			\end{itemize}
		\end{column}		
	\end{columns}
\end{frame}

\begin{frame}[t]{Klassifizierung mit Tensorflow - Nächste Schritte}
	\begin{itemize}
		\item Finden einer geeigneten Verlustfunktion
		\item Multi-Label-Evaluation
		\item Verwenden von Gewichten
	\end{itemize}
\end{frame}

\begin{frame}[t]{Klassifizierung mit XGBoost}
	\begin{itemize}
		\item Bibliothek für GPU-unterstützte und verteilte Berechnung von \emph{Gradient Boosted Trees}
	\end{itemize}
	Vorteile:
	\begin{itemize}
		\item liefert gute Ergebnisse für tabulare Daten
		\item Scikit-learn API vorhanden $\rightarrow$ Verwendung der Scikit-learn Infrastruktur gut möglich, insbesondere \emph{OneVsRestClassifier}
		\item gute Interpretierbarkeit $\rightarrow$ 
	\end{itemize}
\end{frame}

\begin{frame}[t]{Hyperparametertuning mit randomisierter Suche und Bayesian Optimization}
	
\end{frame}

\section{Probleme und offene Fragen}

\begin{frame}[t]{Learning Rate und N\_Estimators}
	
\end{frame}

\begin{frame}[t]{NaN-Werte in den Labeln}
	
\end{frame}

\begin{frame}[t]{}
	
\end{frame}

\section{Pläne für die Zukunft}

\end{document}
