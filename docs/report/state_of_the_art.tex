\section{State of the Art}
Multiple works are dedicated to the topic of human context recognition. Which results in a variety of different approaches to solve this problem. However, data collecting was not easy in the past and often needed multiple obstructive sensors tied to the body and utilized scripting of complex user activities to gather labels. A overview of some data sets and utilized techniques can be found in \cite{Ramasamy18} and \cite{Lara13}. Traditionally most of these tasks were attempted to solved with Hidden Markov models \cite{Lee11} and SVM \cite{Anguita12}. 
With increasing accuracy of modern smartphones sensors and utilization of smart watches natural human behavior data could be collected in-the-wild. Thus increases the difficulty of human context recognition, but also provides a potential usage in a real use case scenario.  One of he challenges is the influence on the classification results by using different hardware \cite{Stisen15} and also the potential incompleteness of available sensor label data for classification. Due to this the task of human context recognition in-the-wild is a complex and challenging classification problem. 
To solve this, most up to date researches utilize techniques of deep learning. Vaizman et al., the authors of the \gl The ExtraSensory Dataset\gr  used in this report, provided a baseline classificator using logistic regression as a linear classifier for each sensor and ensemble methods to combine the results \cite{Vaizman17}. This initial baseline was later improved to handle unbalanced data sets and incomplete labeling by using a feed-forward neural network. The used technique was reciprocal instance weighting the imbalanced data. Additionally, missing labels were given a weight of zero to prevent their influence on the trained model. The best reported result was a network with two hidden layer, were each layer had 16 dimension. The balanced accuracy was 77.3 \% \cite{Vaizman18}. 

Deep neural networks highly depend on the quality and amount of training data, but in real world scenarios there is always the possibility of missing sensor data. To address this problem different approaches were made. One approach was to train separate neural networks for the different sensors and then combine their output in shared layers on an additional network. Resulting in a ensemble network with higher tolerance towards missing sensor data and comparable results as reported by Vaizman et al. \cite{Saeed18}. Other approaches used an auto encoder to synthesize realistic samples and thereby effectively calculating realistic complete sample data. Using this synthetic data to train a fully-connected classification network was shown to almost reproduce the same accuracy, but with higher tolerance towards missing sensor data \cite{Saeed18-2}. Essentially this technique also allows dealing with the incomplete labeling problem. Other attempts to solve this issue are matrix co-compleation \cite{Xu18} or integrating out the missing labels in a probabilistic model that can automatically learn and exploit multilabel correlations \cite{Bi14}.

A recent paper proposed to use XGBoost for indoor human activity recognition and its potential to out perform other classical classifiers \cite{Zhang19}. Therefore, we attempt to compare this api in this work and compere it with other classifiers on a more general data set. 
