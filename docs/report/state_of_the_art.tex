\section{State of the Art}
There is a large number of works dedicated to the topic of human context recognition, resulting in a variety of different approaches to solve these problems. However, data collecting was not easy in the past and often needed multiple obstructive sensors tied to the body and utilized scripting of complex user activities. An overview of some datasets and utilized techniques of this time can be found in \cite{Ramasamy18} and \cite{Lara13}. Traditionally most of these tasks were attempted to solve with Hidden Markov models \cite{Lee11} and Support Vector Machines \cite{Anguita12}. 

With increasing accuracy and presence of modern smartphone sensors and utilization of smart watches, natural human behavior data can today be collected in-the-wild. This possibility of data collection comes with a wider range of contexts, which of course increases the difficulty of human context recognition. At the same time more data in general and potential usage in real use case scenarios is provided.  One of the challenges lies in the influence on the classification results by using different hardware \cite{Stisen15} and also the potential incompleteness of available sensor data and sensor label data for classification. Due to this, the task of human context recognition in-the-wild is a complex and challenging classification problem. 

To solve this, most recent researches utilize techniques of deep learning. Vaizman et al., the authors of the \gl ExtraSensory Dataset\gr{} utilized in this report, provided a baseline classifier using logistic regression as a linear classifier for each sensor and ensemble methods to combine the results \cite{Vaizman17}. This initial baseline was later improved to handle imbalanced datasets and incomplete labeling by using a feed-forward neural network. As a technique reciprocal instance weighting the imbalanced data was involved. Additionally, missing labels were assigned a weight of zero to prevent their influence on the trained model. The best reported result was a network with two hidden layer, where each layer had 16 dimensions, which produced a balanced accuracy of 77.3\% \cite{Vaizman18}. 

Deep neural networks highly depend on the quality and amount of training data, but in real world scenarios there is always a high probability of missing sensor data. Different approaches address this problem. One approach consists in training separate neural networks for the different sensors and then combining their output in shared layers on an additional network. This results in an ensemble network with higher tolerance towards missing sensor data and comparable results as reported by Vaizman et al. \cite{Saeed18}. Other approaches use an auto encoder to synthesize realistic samples and thereby effectively calculating realistic complete sample data. Using this synthetic data to train a fully-connected classification network was shown to almost reproduce the same accuracy, but with higher tolerance towards missing sensor data \cite{Saeed18-2}. Essentially this technique also allows dealing with the incomplete labeling problem. Other attempts to solve this issue are matrix co-completion \cite{Xu18} or integrating out the missing labels in a probabilistic model that can automatically learn and exploit multilabel correlations \cite{Bi14}.

A recent paper proposed to use XGBoost for indoor human activity recognition and its potential to out perform other classical classifiers \cite{Zhang19}. Therefore, we attempt to include this API in this work and compare it with other classifiers on a more general dataset. 
