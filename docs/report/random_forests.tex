\subsection{Random Forests}\label{subsec:random_forests}

A random forest is a classification method in which an ensemble of decision trees is created which are not correlated if possible. The underlying strategy, as with any ensemble classifier, is to create a stronger learner from weak learners. This is why the uncorrelatedness of the individual decision trees plays an important role, because the addition of a correlating tree hardly improves classification results in general. In the context of random forests, procedures exist to ensure low levels of correlations. One of these methods is found in feature subsampling where only a smaller subset of features is randomly chosen as training data in every iteration of decision tree creation. This method helps to prevent overfitting, because not every tree in the forest was trained on the same dataset. The evaluation of the ensemble usually takes place through some sort of a voting mechanism. \cite{Jiang}

