\subsection{Evaluation Instance Weighting}

Some papers report instance weighting as one major method to improve the balanced accuracy score of a trained model. Consequently, we attempted to reproduce these results. We conducted 5 fold cross evaluation on the provided features of the entire ExtraSensory dataset with and without instance weighting. For comparison reasons and to determine the best of our implemented classifiers, this was done for random forest, XGBoost, logistic regression and naive bayas classifiers. 
We were not able to reproduce the improvement reported in literature (\cite{Vaizman18}, \cite{Saeed18}). Instead each classifier lost about 5-8 percent points in accuracy. In the following we discuss which sources of failure might be excluded and a possible explanations of the behavior. 
The first obvious possible source of failure could be a bad implementation. We think this is not the case for the following reasons. First of all if the data handling would be wrong there should be an effect on the entirety experiments. This was not observed. Second we trained different models utilizing different API's. Since the error was not only observed for just a subsection of the API's we can consequently assume that the implementations of the classifiers are correct. Otherwise the error would be spreader very far and must have been noticed by members of the large community using these API's. One additional possibility is a bad implementation of the weight itself. As weighting function we used the count of the opposite label value divided by the count of the current label value. This a fairly simple implementation and was double checked. Therefore we assume our implementation to be correct. 
The second possible source of the accuracy loss is an issue with the dataset itself. The reason is the highly unbalanced representations of true and false example for many labels as already discussed in the dataset introduction. One example is the elevator label with just 200 positive, but 70996 negative labels. The quotient of negative to positive value counts is almost 355. While this is the worst case example there many labels with a instance weighting above 50. Thus drastically increases the influence of the training process of these underrepresented positive and also some negative labels. If the few labels do not, and most likely will not, provide a sufficient representation of the labels a representative model can not be trained which can not provide a good classification for those labels. In addition the model is trained to an increasing false positive or false negative rate, because the tolerance towards those representatives is pushed.
To prevent this over boosting we tested regulating the used weights of the instance weighting by reducing the growth rate. This was done by applying the square root function. In fact the regularization did reduce the accuracy loss by about 3 percent points, but still an consistent decrease in balanced accuracy was observed. This theory could not be proven or disproved by us due to limited research time and remains an interesting challenge for future research. Furthermore this problem can not be the only influence, since Vaizman et al. performed very similar experiments with the same dataset and directly contradicted our findings.